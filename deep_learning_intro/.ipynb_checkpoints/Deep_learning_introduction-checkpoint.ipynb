{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple MLP for classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features pixel intensities 0 to 255\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0xa1310a5a20>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0xa1310be4e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0xa1310be9e8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0xa1310bebe0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04690405, -0.04514444, -0.01362551, ..., -0.06085352,\n",
       "        -0.06475659,  0.05649413],\n",
       "       [-0.04031773,  0.06183726,  0.0526735 , ..., -0.0742455 ,\n",
       "        -0.06252122,  0.06317964],\n",
       "       [-0.07141963,  0.02740433,  0.00658911, ...,  0.01896454,\n",
       "        -0.06114722,  0.00384099],\n",
       "       ...,\n",
       "       [ 0.02013084, -0.01554845,  0.00616011, ...,  0.02722456,\n",
       "         0.03215412, -0.05628205],\n",
       "       [-0.05315097,  0.01941398,  0.00307952, ..., -0.00858025,\n",
       "        -0.01682663,  0.06048398],\n",
       "       [-0.01671491,  0.02370487, -0.00281236, ..., -0.05152252,\n",
       "         0.04609318, -0.03934027]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biases are initialized to zeros, we can set kernel_initializer for use different initialization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse categorical crossentropy vs categorical crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It depends of label: \n",
    "\n",
    "Sparse label > target class index 0 to 9 in this case\n",
    "\n",
    "Categorical label > target class one-hot vector [0,0,0,0,0,0,1,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert sparse label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = keras.utils.to_categorical(A, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.argmax(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s 100us/sample - loss: 0.7321 - accuracy: 0.7595 - val_loss: 0.5129 - val_accuracy: 0.8320\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.4959 - accuracy: 0.8271 - val_loss: 0.4599 - val_accuracy: 0.8436\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.4474 - accuracy: 0.8424 - val_loss: 0.4084 - val_accuracy: 0.8604\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.4199 - accuracy: 0.8524 - val_loss: 0.4207 - val_accuracy: 0.8554\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.3988 - accuracy: 0.8602 - val_loss: 0.3932 - val_accuracy: 0.8622\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.3821 - accuracy: 0.8660 - val_loss: 0.3648 - val_accuracy: 0.8788\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.3692 - accuracy: 0.8694 - val_loss: 0.3678 - val_accuracy: 0.8754\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.3559 - accuracy: 0.8735 - val_loss: 0.3591 - val_accuracy: 0.8722\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s 82us/sample - loss: 0.3457 - accuracy: 0.8773 - val_loss: 0.3516 - val_accuracy: 0.8726\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.3358 - accuracy: 0.8802 - val_loss: 0.3427 - val_accuracy: 0.8788\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.3262 - accuracy: 0.8838 - val_loss: 0.3315 - val_accuracy: 0.8822\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 0.3182 - accuracy: 0.8861 - val_loss: 0.3445 - val_accuracy: 0.8820\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.3116 - accuracy: 0.8890 - val_loss: 0.3319 - val_accuracy: 0.8824\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.3042 - accuracy: 0.8898 - val_loss: 0.3300 - val_accuracy: 0.8820\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.2967 - accuracy: 0.8939 - val_loss: 0.3674 - val_accuracy: 0.8662\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.2914 - accuracy: 0.8947 - val_loss: 0.3411 - val_accuracy: 0.8770\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.2853 - accuracy: 0.8969 - val_loss: 0.3188 - val_accuracy: 0.8876\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.2803 - accuracy: 0.8996 - val_loss: 0.3235 - val_accuracy: 0.8864\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.2741 - accuracy: 0.9016 - val_loss: 0.3098 - val_accuracy: 0.8904\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2696 - accuracy: 0.9034 - val_loss: 0.3077 - val_accuracy: 0.8932\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2647 - accuracy: 0.9044 - val_loss: 0.3046 - val_accuracy: 0.8932\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s 82us/sample - loss: 0.2587 - accuracy: 0.9077 - val_loss: 0.3125 - val_accuracy: 0.8878\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2539 - accuracy: 0.9086 - val_loss: 0.3292 - val_accuracy: 0.8824\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2501 - accuracy: 0.9093 - val_loss: 0.3004 - val_accuracy: 0.8934\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2458 - accuracy: 0.9114 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2421 - accuracy: 0.9126 - val_loss: 0.3016 - val_accuracy: 0.8924\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2371 - accuracy: 0.9149 - val_loss: 0.3114 - val_accuracy: 0.8850\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.2334 - accuracy: 0.9154 - val_loss: 0.3010 - val_accuracy: 0.8888\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2296 - accuracy: 0.9171 - val_loss: 0.3068 - val_accuracy: 0.8938\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.2257 - accuracy: 0.9180 - val_loss: 0.2900 - val_accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 30,\n",
       " 'steps': 1719,\n",
       " 'samples': 55000,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'accuracy', 'val_loss', 'val_accuracy']}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.3255 - accuracy: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.325472375535965, 0.8857]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on new instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple MLP for regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_valid_sc = sc.transform(X_valid)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 1.1724 - val_loss: 0.8398\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5768 - val_loss: 0.5562\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4828 - val_loss: 0.5141\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4574 - val_loss: 0.4997\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4452 - val_loss: 0.4845\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4387 - val_loss: 0.4707\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4291 - val_loss: 0.4728\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4265 - val_loss: 0.4621\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4189 - val_loss: 0.4468\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4151 - val_loss: 0.4439\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4517 - val_loss: 0.4506\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4071 - val_loss: 0.4416\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4027 - val_loss: 0.4320\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3965 - val_loss: 0.4355\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3938 - val_loss: 0.4237\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3928 - val_loss: 0.4240\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3861 - val_loss: 0.4256\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3854 - val_loss: 0.4130\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3854 - val_loss: 0.4071\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3781 - val_loss: 0.4095\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train_sc.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "history = model.fit(X_train_sc, y_train,\n",
    "                    validation_data=(X_valid_sc, y_valid), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 16us/sample - loss: 0.4022\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_sc, y_test)\n",
    "X_new = X_test_sc[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8723559],\n",
       "       [1.0487727],\n",
       "       [2.4959385]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train_sc.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.9507 - val_loss: 0.5895\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5332 - val_loss: 0.5128\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4658 - val_loss: 0.4849\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4299 - val_loss: 0.4570\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4528 - val_loss: 0.4547\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4093 - val_loss: 0.4360\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4034 - val_loss: 0.4248\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4477 - val_loss: 0.4105\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3778 - val_loss: 0.4019\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4314 - val_loss: 0.3936\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3718 - val_loss: 0.3903\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3562 - val_loss: 0.3764\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4112 - val_loss: 0.3774\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3471 - val_loss: 0.3800\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3468 - val_loss: 0.3641\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3362 - val_loss: 0.3611\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3371 - val_loss: 0.3681\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3329 - val_loss: 0.3561\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3267 - val_loss: 0.3700\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4392 - val_loss: 0.3635\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "history = model.fit(X_train_sc, y_train,\n",
    "                    validation_data=(X_valid_sc, y_valid), epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 16us/sample - loss: 0.3631\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_sc, y_test)\n",
    "X_new = X_test_sc[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0855343],\n",
       "       [1.141564 ],\n",
       "       [2.7132635]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send subset through deep path, and another through short path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 1.8726 - val_loss: 1.0292\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.8326 - val_loss: 0.7897\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6764 - val_loss: 0.6994\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6132 - val_loss: 0.6661\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.5761 - val_loss: 0.6152\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5507 - val_loss: 0.5914\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5317 - val_loss: 0.5836\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5176 - val_loss: 0.5628\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5090 - val_loss: 0.5671\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5015 - val_loss: 0.5480\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4952 - val_loss: 0.5394\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4919 - val_loss: 0.5345\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4881 - val_loss: 0.5399\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4843 - val_loss: 0.5388\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4786 - val_loss: 0.5327\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4764 - val_loss: 0.5260\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4734 - val_loss: 0.5232\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4705 - val_loss: 0.5484\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4668 - val_loss: 0.5114\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4656 - val_loss: 0.5093\n",
      "5160/5160 [==============================] - 0s 19us/sample - loss: 0.4889\n"
     ]
    }
   ],
   "source": [
    "X_train_A, X_train_B = X_train_sc[:, :5], X_train_sc[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid_sc[:, :5], X_valid_sc[:, 2:]\n",
    "X_test_A, X_test_B = X_test_sc[:, :5], X_test_sc[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 105us/sample - loss: 0.9473 - main_output_loss: 0.8583 - aux_output_loss: 1.7460 - val_loss: 0.6413 - val_main_output_loss: 0.5759 - val_aux_output_loss: 1.2302\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5608 - main_output_loss: 0.5045 - aux_output_loss: 1.0692 - val_loss: 0.5851 - val_main_output_loss: 0.5346 - val_aux_output_loss: 1.0403\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5341 - main_output_loss: 0.4898 - aux_output_loss: 0.9375 - val_loss: 0.5500 - val_main_output_loss: 0.5106 - val_aux_output_loss: 0.9054\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4995 - main_output_loss: 0.4626 - aux_output_loss: 0.8309 - val_loss: 0.5097 - val_main_output_loss: 0.4760 - val_aux_output_loss: 0.8137\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4786 - main_output_loss: 0.4465 - aux_output_loss: 0.7678 - val_loss: 0.5007 - val_main_output_loss: 0.4706 - val_aux_output_loss: 0.7724\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4637 - main_output_loss: 0.4350 - aux_output_loss: 0.7215 - val_loss: 0.4822 - val_main_output_loss: 0.4544 - val_aux_output_loss: 0.7328\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4594 - main_output_loss: 0.4344 - aux_output_loss: 0.6849 - val_loss: 0.4815 - val_main_output_loss: 0.4571 - val_aux_output_loss: 0.7020\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4425 - main_output_loss: 0.4187 - aux_output_loss: 0.6558 - val_loss: 0.7122 - val_main_output_loss: 0.7179 - val_aux_output_loss: 0.6607\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4367 - main_output_loss: 0.4140 - aux_output_loss: 0.6398 - val_loss: 0.4605 - val_main_output_loss: 0.4375 - val_aux_output_loss: 0.6682\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4243 - main_output_loss: 0.4026 - aux_output_loss: 0.6191 - val_loss: 0.4512 - val_main_output_loss: 0.4271 - val_aux_output_loss: 0.6689\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4264 - main_output_loss: 0.4071 - aux_output_loss: 0.5999 - val_loss: 0.4821 - val_main_output_loss: 0.4668 - val_aux_output_loss: 0.6199\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4101 - main_output_loss: 0.3899 - aux_output_loss: 0.5906 - val_loss: 0.4355 - val_main_output_loss: 0.4165 - val_aux_output_loss: 0.6073\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4135 - main_output_loss: 0.3950 - aux_output_loss: 0.5802 - val_loss: 0.4228 - val_main_output_loss: 0.4057 - val_aux_output_loss: 0.5776\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3981 - main_output_loss: 0.3795 - aux_output_loss: 0.5671 - val_loss: 0.4205 - val_main_output_loss: 0.4037 - val_aux_output_loss: 0.5718\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3886 - main_output_loss: 0.3709 - aux_output_loss: 0.5469 - val_loss: 0.4185 - val_main_output_loss: 0.3999 - val_aux_output_loss: 0.5871\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3950 - main_output_loss: 0.3798 - aux_output_loss: 0.5308 - val_loss: 0.4052 - val_main_output_loss: 0.3898 - val_aux_output_loss: 0.5447\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3773 - main_output_loss: 0.3614 - aux_output_loss: 0.5202 - val_loss: 0.4078 - val_main_output_loss: 0.3902 - val_aux_output_loss: 0.5666\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3714 - main_output_loss: 0.3562 - aux_output_loss: 0.5088 - val_loss: 0.4036 - val_main_output_loss: 0.3906 - val_aux_output_loss: 0.5203\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3678 - main_output_loss: 0.3529 - aux_output_loss: 0.5018 - val_loss: 0.4129 - val_main_output_loss: 0.3990 - val_aux_output_loss: 0.5382\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3638 - main_output_loss: 0.3494 - aux_output_loss: 0.4933 - val_loss: 0.3869 - val_main_output_loss: 0.3732 - val_aux_output_loss: 0.5107\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "[X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 21us/sample - loss: 0.3864 - main_output_loss: 0.3719 - aux_output_loss: 0.5010\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "[X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Subclassing API to build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.9705 - val_loss: 0.8136\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5269 - val_loss: 0.5793\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4702 - val_loss: 0.5030\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4537 - val_loss: 0.4892\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4386 - val_loss: 0.4708\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4304 - val_loss: 0.4663\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4240 - val_loss: 0.4568\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4156 - val_loss: 0.4511\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4115 - val_loss: 0.4431\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4049 - val_loss: 0.4385\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4001 - val_loss: 0.4316\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3963 - val_loss: 0.4333\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3919 - val_loss: 0.4254\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3885 - val_loss: 0.4195\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3851 - val_loss: 0.4136\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3835 - val_loss: 0.4121\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3824 - val_loss: 0.4161\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3792 - val_loss: 0.4100\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3746 - val_loss: 0.4125\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3722 - val_loss: 0.4027\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train_sc.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "history = model.fit(X_train_sc, y_train,\n",
    "                    validation_data=(X_valid_sc, y_valid), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.8150\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.7022\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4799\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4576\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4451\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4384\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4294\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4235\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4221\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4128\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train_sc.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train_sc, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use validation set during training, save_best_only=True will only save the model when its performance on the validation set is the best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4137 - val_loss: 0.4436\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4065 - val_loss: 0.4334\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4032 - val_loss: 0.4364\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4118 - val_loss: 0.4412\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3935 - val_loss: 0.4263\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3903 - val_loss: 0.4236\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3952 - val_loss: 0.4250\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3936 - val_loss: 0.4212\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3852 - val_loss: 0.4107\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3804 - val_loss: 0.4058\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train_sc, y_train, epochs=10,\n",
    "                    validation_data=(X_valid_sc, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # roll back to best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EarlyStopping will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the patience argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3786 - val_loss: 0.4158\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3834 - val_loss: 0.4058\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4205 - val_loss: 0.4119\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3917 - val_loss: 0.4069\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3805 - val_loss: 0.4126\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3695 - val_loss: 0.4081\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3640 - val_loss: 0.3955\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3616 - val_loss: 0.3983\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3590 - val_loss: 0.3933\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3569 - val_loss: 0.3875\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3542 - val_loss: 0.3879\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3694 - val_loss: 0.3805\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3526 - val_loss: 0.3795\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3742 - val_loss: 0.3992\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3529 - val_loss: 0.3908\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3477 - val_loss: 0.3766\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3482 - val_loss: 0.3778\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3443 - val_loss: 0.3971\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3453 - val_loss: 0.3800\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3429 - val_loss: 0.3729\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3386 - val_loss: 0.3688\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3386 - val_loss: 0.3655\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3360 - val_loss: 0.3672\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3372 - val_loss: 0.3701\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3338 - val_loss: 0.3648\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3358 - val_loss: 0.4058\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3529 - val_loss: 0.3726\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3321 - val_loss: 0.3664\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3301 - val_loss: 0.3650\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3324 - val_loss: 0.3606\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3280 - val_loss: 0.3612\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3275 - val_loss: 0.3621\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3287 - val_loss: 0.3672\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3283 - val_loss: 0.3536\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3268 - val_loss: 0.3612\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3255 - val_loss: 0.3735\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3256 - val_loss: 0.3574\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3256 - val_loss: 0.3919\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3232 - val_loss: 0.3578\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3222 - val_loss: 0.3554\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3219 - val_loss: 0.3546\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3208 - val_loss: 0.3559\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3212 - val_loss: 0.3510\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3188 - val_loss: 0.3558\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3200 - val_loss: 0.3508\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3184 - val_loss: 0.3479\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3253 - val_loss: 0.3555\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3178 - val_loss: 0.3603\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3176 - val_loss: 0.3510\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3163 - val_loss: 0.3489\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3168 - val_loss: 0.3539\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3202 - val_loss: 0.3523\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3153 - val_loss: 0.3467\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3163 - val_loss: 0.3669\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3182 - val_loss: 0.3507\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3150 - val_loss: 0.3462\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3149 - val_loss: 0.3510\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3133 - val_loss: 0.3489\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3137 - val_loss: 0.3446\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3118 - val_loss: 0.3432\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3138 - val_loss: 0.3465\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3120 - val_loss: 0.3512\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3121 - val_loss: 0.3500\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3113 - val_loss: 0.3453\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3124 - val_loss: 0.3462\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3107 - val_loss: 0.3532\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3113 - val_loss: 0.3486\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3149 - val_loss: 0.3474\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3100 - val_loss: 0.3545\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3091 - val_loss: 0.3472\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train_sc, y_train, epochs=100,\n",
    "                    validation_data=(X_valid_sc, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3136 - val_loss: 13402.6182\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3115 - val_loss: 33261.4771\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3124 - val_loss: 12427.6404\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3121 - val_loss: 13500.5234\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3104 - val_loss: 17578.2785\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3130 - val_loss: 14464.0698\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3108 - val_loss: 21643.9631\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3116 - val_loss: 39008.0647\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3104 - val_loss: 21570.4902\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3092 - val_loss: 25598.7798\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3099 - val_loss: 33947.8629\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3110 - val_loss: 30617.1006\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3105 - val_loss: 22279.2479\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3090 - val_loss: 13387.3005\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3126 - val_loss: 29286.6391\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3108 - val_loss: 23282.4672\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3155 - val_loss: 34488.3034\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3114 - val_loss: 56636.4028\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3090 - val_loss: 26153.0793\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3090 - val_loss: 30185.9629\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3086 - val_loss: 44828.6721\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3082 - val_loss: 25078.9989\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3066 - val_loss: 16368.6339\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3084 - val_loss: 42331.9277\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3065 - val_loss: 57694.6374\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3075 - val_loss: 55908.1982\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3100 - val_loss: 35395.8863\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3053 - val_loss: 37922.9175\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3048 - val_loss: 55718.3792\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3043 - val_loss: 33966.2037\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train_sc, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 6376."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 1.1792 - val_loss: 0.7847\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6617 - val_loss: 0.6789\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5720 - val_loss: 0.6081\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5256 - val_loss: 0.5713\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4956 - val_loss: 0.5468\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4812 - val_loss: 0.5309\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4704 - val_loss: 0.5202\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4633 - val_loss: 0.5102\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4573 - val_loss: 0.5041\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4531 - val_loss: 0.4973\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4489 - val_loss: 0.4917\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4451 - val_loss: 0.4910\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4417 - val_loss: 0.4861\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4391 - val_loss: 0.4816\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4355 - val_loss: 0.4761\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4330 - val_loss: 0.4732\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4309 - val_loss: 0.4708\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4284 - val_loss: 0.4689\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4263 - val_loss: 0.4689\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4237 - val_loss: 0.4654\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4227 - val_loss: 0.4606\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4204 - val_loss: 0.4604\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4186 - val_loss: 0.4559\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4181 - val_loss: 0.4550\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4155 - val_loss: 0.4534\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4136 - val_loss: 0.4488\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4121 - val_loss: 0.4505\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4104 - val_loss: 0.4466\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4088 - val_loss: 0.4458\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4092 - val_loss: 0.4451\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4063 - val_loss: 0.4425\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4051 - val_loss: 0.4440\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4034 - val_loss: 0.4410\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4022 - val_loss: 0.4380\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4003 - val_loss: 0.4376\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3997 - val_loss: 0.4374\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3983 - val_loss: 0.4361\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3969 - val_loss: 0.4336\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3971 - val_loss: 0.4359\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3949 - val_loss: 0.4303\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3955 - val_loss: 0.4316\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3924 - val_loss: 0.4284\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3925 - val_loss: 0.4281\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3905 - val_loss: 0.4295\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3888 - val_loss: 0.4247\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3883 - val_loss: 0.4241\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3869 - val_loss: 0.4251\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3859 - val_loss: 0.4206\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3849 - val_loss: 0.4211\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3843 - val_loss: 0.4190\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3828 - val_loss: 0.4221\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3822 - val_loss: 0.4167\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3809 - val_loss: 0.4184\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3812 - val_loss: 0.4169\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3793 - val_loss: 0.4131\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3785 - val_loss: 0.4207\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3789 - val_loss: 0.4115\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3766 - val_loss: 0.4177\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3756 - val_loss: 0.4124\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3752 - val_loss: 0.4107\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3744 - val_loss: 0.4132\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3735 - val_loss: 0.4096\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3722 - val_loss: 0.4109\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3749 - val_loss: 0.4101\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3711 - val_loss: 0.4057\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3702 - val_loss: 0.4100\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3702 - val_loss: 0.4070\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3685 - val_loss: 0.4076\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3682 - val_loss: 0.4071\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3676 - val_loss: 0.4074\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3664 - val_loss: 0.4050\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3666 - val_loss: 0.4037\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3653 - val_loss: 0.4034\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3662 - val_loss: 0.4022\n",
      "Epoch 75/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3649 - val_loss: 0.4006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3639 - val_loss: 0.4032\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3647 - val_loss: 0.3989\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3630 - val_loss: 0.3997\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3625 - val_loss: 0.3990\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3615 - val_loss: 0.3982\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3610 - val_loss: 0.3980\n",
      "Epoch 82/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3599 - val_loss: 0.4032\n",
      "Epoch 83/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3601 - val_loss: 0.3943\n",
      "Epoch 84/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3601 - val_loss: 0.3969\n",
      "Epoch 85/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3587 - val_loss: 0.3966\n",
      "Epoch 86/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3590 - val_loss: 0.3989\n",
      "Epoch 87/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3586 - val_loss: 0.3908\n",
      "Epoch 88/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3578 - val_loss: 0.3997\n",
      "Epoch 89/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3570 - val_loss: 0.3989\n",
      "Epoch 90/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3572 - val_loss: 0.3938\n",
      "Epoch 91/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3564 - val_loss: 0.3942\n",
      "Epoch 92/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3561 - val_loss: 0.3911\n",
      "Epoch 93/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3556 - val_loss: 0.3915\n",
      "Epoch 94/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3558 - val_loss: 0.3920\n",
      "Epoch 95/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3549 - val_loss: 0.3884\n",
      "Epoch 96/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3545 - val_loss: 0.3899\n",
      "Epoch 97/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3539 - val_loss: 0.3888\n",
      "Epoch 98/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3549 - val_loss: 0.3878\n",
      "Epoch 99/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3537 - val_loss: 0.3904\n",
      "Epoch 100/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3532 - val_loss: 0.3898\n",
      "5160/5160 [==============================] - 0s 17us/sample - loss: 0.3824\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train_sc, y_train, epochs=100,\n",
    "              validation_data=(X_valid_sc, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "mse_test = keras_reg.score(X_test_sc, y_test)\n",
    "X_new = X_test_sc[:3]\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.38241735953231193"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9921207, 1.1273474, 2.3716564], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.042, 1.938, 2.905])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 3.1647 - val_loss: 1.4850\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.9474 - val_loss: 0.7608\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6023 - val_loss: 0.6011\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5361 - val_loss: 0.5671\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5240 - val_loss: 0.5669\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5196 - val_loss: 0.5603\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5200 - val_loss: 0.5603\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5200 - val_loss: 0.5664\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5196 - val_loss: 0.5725\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5198 - val_loss: 0.5648\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5195 - val_loss: 0.5702\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5186 - val_loss: 0.5600\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5195 - val_loss: 0.5599\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5190 - val_loss: 0.5610\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5191 - val_loss: 0.5594\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5197 - val_loss: 0.5633\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5194 - val_loss: 0.5690\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5192 - val_loss: 0.5692\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5192 - val_loss: 0.5668\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5182 - val_loss: 0.5596\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5189 - val_loss: 0.5594\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5190 - val_loss: 0.5700\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5186 - val_loss: 0.5749\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5193 - val_loss: 0.5676\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5188 - val_loss: 0.5716\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5191 - val_loss: 0.5719\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5167 - val_loss: 0.5564\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5194 - val_loss: 0.5712\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5190 - val_loss: 0.5733\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5191 - val_loss: 0.5747\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5189 - val_loss: 0.5746\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5189 - val_loss: 0.5639\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5190 - val_loss: 0.5698\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5186 - val_loss: 0.5666\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5186 - val_loss: 0.5747\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5192 - val_loss: 0.5674\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5187 - val_loss: 0.5615\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4994\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 3.0762 - val_loss: 1.7414\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.1594 - val_loss: 0.9317\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7541 - val_loss: 0.7517\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6565 - val_loss: 0.6976\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6227 - val_loss: 0.6715\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6045 - val_loss: 0.6595\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5917 - val_loss: 0.6483\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5809 - val_loss: 0.6375\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5718 - val_loss: 0.6314\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5639 - val_loss: 0.6239\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5569 - val_loss: 0.6199\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5508 - val_loss: 0.6124\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5455 - val_loss: 0.6081\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5409 - val_loss: 0.6044\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5368 - val_loss: 0.5990\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5334 - val_loss: 0.5958\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5304 - val_loss: 0.5964\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5275 - val_loss: 0.5974\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5253 - val_loss: 0.5927\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5225 - val_loss: 0.5840\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5215 - val_loss: 0.5848\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5196 - val_loss: 0.5905\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5183 - val_loss: 0.5928\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5173 - val_loss: 0.5888\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5159 - val_loss: 0.5875\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5150 - val_loss: 0.5872\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5130 - val_loss: 0.5751\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5137 - val_loss: 0.5859\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5128 - val_loss: 0.5861\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5121 - val_loss: 0.5889\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5117 - val_loss: 0.5827\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5111 - val_loss: 0.5777\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5110 - val_loss: 0.5813\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5102 - val_loss: 0.5755\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5097 - val_loss: 0.5854\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5096 - val_loss: 0.5758\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5097 - val_loss: 0.5759\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.5286\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 91us/sample - loss: 3.0723 - val_loss: 1.5784\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 1.0636 - val_loss: 0.8149\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.6691 - val_loss: 0.6614\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5823 - val_loss: 0.6278\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5596 - val_loss: 0.6153\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5506 - val_loss: 0.6106\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5455 - val_loss: 0.6073\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5417 - val_loss: 0.6026\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5385 - val_loss: 0.6018\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5358 - val_loss: 0.5998\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5334 - val_loss: 0.5929\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5313 - val_loss: 0.5901\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5293 - val_loss: 0.5890\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5275 - val_loss: 0.5869\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5259 - val_loss: 0.5849\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5244 - val_loss: 0.5795\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5231 - val_loss: 0.5808\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5219 - val_loss: 0.5801\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5209 - val_loss: 0.5776\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5199 - val_loss: 0.5757\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5190 - val_loss: 0.5750\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5182 - val_loss: 0.5718\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5175 - val_loss: 0.5712\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5168 - val_loss: 0.5706\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5161 - val_loss: 0.5698\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5156 - val_loss: 0.5691\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5151 - val_loss: 0.5667\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5146 - val_loss: 0.5645\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5142 - val_loss: 0.5659\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5139 - val_loss: 0.5658\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5133 - val_loss: 0.5629\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5131 - val_loss: 0.5641\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5129 - val_loss: 0.5636\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5126 - val_loss: 0.5639\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5123 - val_loss: 0.5612\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5121 - val_loss: 0.5626\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5118 - val_loss: 0.5633\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5118 - val_loss: 0.5624\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5115 - val_loss: 0.5606\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5114 - val_loss: 0.5609\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5112 - val_loss: 0.5583\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5109 - val_loss: 0.5585\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5110 - val_loss: 0.5580\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5108 - val_loss: 0.5574\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5107 - val_loss: 0.5588\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5106 - val_loss: 0.5592\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5105 - val_loss: 0.5579\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5105 - val_loss: 0.5585\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5104 - val_loss: 0.5588\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5103 - val_loss: 0.5582\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5101 - val_loss: 0.5596\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5102 - val_loss: 0.5561\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5102 - val_loss: 0.5569\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5100 - val_loss: 0.5559\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5099 - val_loss: 0.5546\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5100 - val_loss: 0.5563\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5099 - val_loss: 0.5570\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5098 - val_loss: 0.5549\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5099 - val_loss: 0.5563\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5098 - val_loss: 0.5544\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5097 - val_loss: 0.5569\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5096 - val_loss: 0.5588\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5097 - val_loss: 0.5573\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5096 - val_loss: 0.5545\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5097 - val_loss: 0.5558\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5097 - val_loss: 0.5546\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5096 - val_loss: 0.5541\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5097 - val_loss: 0.5546\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5096 - val_loss: 0.5546\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5096 - val_loss: 0.5539\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5096 - val_loss: 0.5556\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5095 - val_loss: 0.5542\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5095 - val_loss: 0.5531\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5095 - val_loss: 0.5529\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5095 - val_loss: 0.5553\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5095 - val_loss: 0.5564\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5095 - val_loss: 0.5538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5095 - val_loss: 0.5535\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5096 - val_loss: 0.5536\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5095 - val_loss: 0.5548\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5095 - val_loss: 0.5541\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5095 - val_loss: 0.5527\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5095 - val_loss: 0.5540\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5095 - val_loss: 0.5538\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5095 - val_loss: 0.5541\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5095 - val_loss: 0.5552\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5094 - val_loss: 0.5546\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5094 - val_loss: 0.5530\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5094 - val_loss: 0.5531\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5094 - val_loss: 0.5531\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5095 - val_loss: 0.5532\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5094 - val_loss: 0.5547\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.5156\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.4782 - val_loss: 0.5416\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 3.3500 - val_loss: 1.0030\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 32.3356 - val_loss: 1.5194\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 343.0833 - val_loss: 19.3567\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 3378.5406 - val_loss: 557.7223\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 37706.6581 - val_loss: 2879.2659\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 409739.9927 - val_loss: 29831.7457\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 4961132.1045 - val_loss: 235367.9697\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 54854933.8114 - val_loss: 2913413.3898\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 525604722.6540 - val_loss: 92790318.3090\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 6248970857.4222 - val_loss: 376101258.3194\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 57488042560.3638\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 1.4664 - val_loss: 0.6866\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5931 - val_loss: 0.6150\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5965 - val_loss: 0.5903\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5281 - val_loss: 0.5714\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5228 - val_loss: 0.5811\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5201 - val_loss: 0.5600\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5184 - val_loss: 0.5526\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5826 - val_loss: 0.5752\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5108 - val_loss: 0.7142\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5286 - val_loss: 0.5626\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5151 - val_loss: 0.8173\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5557 - val_loss: 0.5537\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5341 - val_loss: 0.5578\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5390 - val_loss: 0.5587\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5285 - val_loss: 0.5560\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5328 - val_loss: 0.5531\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5233 - val_loss: 0.5963\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.5348\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.5477 - val_loss: 0.7016\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6039 - val_loss: 0.6401\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5631 - val_loss: 0.6079\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5404 - val_loss: 0.5994\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5283 - val_loss: 0.5759\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5212 - val_loss: 0.5707\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5180 - val_loss: 0.5850\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5164 - val_loss: 0.5620\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5135 - val_loss: 0.5724\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5131 - val_loss: 0.5800\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5125 - val_loss: 0.5580\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5132 - val_loss: 0.5572\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5127 - val_loss: 0.5598\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5121 - val_loss: 0.5562\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5113 - val_loss: 0.5607\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5119 - val_loss: 0.5456\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5109 - val_loss: 0.5647\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5120 - val_loss: 0.5650\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5122 - val_loss: 0.5554\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5116 - val_loss: 0.5564\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5121 - val_loss: 0.5572\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5112 - val_loss: 0.5487\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5123 - val_loss: 0.5566\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5122 - val_loss: 0.5693\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5114 - val_loss: 0.5519\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5120 - val_loss: 0.5555\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.5172\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 2.9988 - val_loss: 1.3465\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 1.1631 - val_loss: 0.9337\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8252 - val_loss: 0.8183\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7512 - val_loss: 0.7733\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7135 - val_loss: 0.7435\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6868 - val_loss: 0.7206\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6652 - val_loss: 0.7019\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6463 - val_loss: 0.6853\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6303 - val_loss: 0.6705\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6152 - val_loss: 0.6561\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6020 - val_loss: 0.6443\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5891 - val_loss: 0.6324\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5778 - val_loss: 0.6205\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5671 - val_loss: 0.6106\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5574 - val_loss: 0.6008\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5484 - val_loss: 0.5923\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5400 - val_loss: 0.5853\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5322 - val_loss: 0.5777\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5251 - val_loss: 0.5699\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5184 - val_loss: 0.5629\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5121 - val_loss: 0.5568\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5064 - val_loss: 0.5517\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5013 - val_loss: 0.5479\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4965 - val_loss: 0.5421\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4919 - val_loss: 0.5376\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4879 - val_loss: 0.5330\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4837 - val_loss: 0.5283\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4801 - val_loss: 0.5259\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4767 - val_loss: 0.5227\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4734 - val_loss: 0.5191\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4702 - val_loss: 0.5173\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4675 - val_loss: 0.5127\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4649 - val_loss: 0.5095\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4622 - val_loss: 0.5066\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4598 - val_loss: 0.5053\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4574 - val_loss: 0.5030\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4553 - val_loss: 0.4991\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4532 - val_loss: 0.4969\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4513 - val_loss: 0.4955\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4493 - val_loss: 0.4929\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4474 - val_loss: 0.4905\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4459 - val_loss: 0.4895\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4440 - val_loss: 0.4880\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4425 - val_loss: 0.4852\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4408 - val_loss: 0.4833\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4396 - val_loss: 0.4828\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4380 - val_loss: 0.4815\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4366 - val_loss: 0.4788\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4353 - val_loss: 0.4778\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4338 - val_loss: 0.4758\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4326 - val_loss: 0.4758\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4313 - val_loss: 0.4733\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4300 - val_loss: 0.4709\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4291 - val_loss: 0.4716\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4280 - val_loss: 0.4694\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4267 - val_loss: 0.4668\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4256 - val_loss: 0.4657\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4247 - val_loss: 0.4652\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4234 - val_loss: 0.4631\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4226 - val_loss: 0.4627\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4215 - val_loss: 0.4620\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4203 - val_loss: 0.4593\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4196 - val_loss: 0.4579\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4184 - val_loss: 0.4574\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4175 - val_loss: 0.4564\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4168 - val_loss: 0.4557\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4158 - val_loss: 0.4554\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4148 - val_loss: 0.4532\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4139 - val_loss: 0.4533\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4130 - val_loss: 0.4512\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4122 - val_loss: 0.4511\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4114 - val_loss: 0.4491\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4104 - val_loss: 0.4475\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4096 - val_loss: 0.4463\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4089 - val_loss: 0.4461\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4079 - val_loss: 0.4446\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4070 - val_loss: 0.4444\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4062 - val_loss: 0.4433\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4056 - val_loss: 0.4424\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4046 - val_loss: 0.4422\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4038 - val_loss: 0.4406\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4030 - val_loss: 0.4390\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4022 - val_loss: 0.4400\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4015 - val_loss: 0.4370\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4007 - val_loss: 0.4355\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3997 - val_loss: 0.4366\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3990 - val_loss: 0.4362\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3983 - val_loss: 0.4333\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3975 - val_loss: 0.4330\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3968 - val_loss: 0.4318\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3960 - val_loss: 0.4322\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3953 - val_loss: 0.4310\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3947 - val_loss: 0.4301\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3939 - val_loss: 0.4280\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3933 - val_loss: 0.4283\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3923 - val_loss: 0.4284\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3920 - val_loss: 0.4255\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3911 - val_loss: 0.4261\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3906 - val_loss: 0.4256\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3900 - val_loss: 0.4255\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3883\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 2.5871 - val_loss: 1.2275\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.0085 - val_loss: 0.8998\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7907 - val_loss: 0.8166\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7259 - val_loss: 0.7769\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6891 - val_loss: 0.7481\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6618 - val_loss: 0.7238\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6391 - val_loss: 0.7032\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6192 - val_loss: 0.6833\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6014 - val_loss: 0.6662\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5852 - val_loss: 0.6492\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5709 - val_loss: 0.6353\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5579 - val_loss: 0.6220\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5462 - val_loss: 0.6104\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5358 - val_loss: 0.6006\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5265 - val_loss: 0.5905\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5182 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5106 - val_loss: 0.5746\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5039 - val_loss: 0.5679\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4979 - val_loss: 0.5609\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4925 - val_loss: 0.5545\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4875 - val_loss: 0.5493\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4829 - val_loss: 0.5457\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4788 - val_loss: 0.5416\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4749 - val_loss: 0.5364\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4715 - val_loss: 0.5326\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4679 - val_loss: 0.5284\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4649 - val_loss: 0.5255\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4619 - val_loss: 0.5229\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4593 - val_loss: 0.5186\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4566 - val_loss: 0.5161\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4542 - val_loss: 0.5136\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4518 - val_loss: 0.5101\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4497 - val_loss: 0.5082\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4474 - val_loss: 0.5048\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4455 - val_loss: 0.5030\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4434 - val_loss: 0.5009\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4416 - val_loss: 0.4990\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4400 - val_loss: 0.4962\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4382 - val_loss: 0.4947\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4366 - val_loss: 0.4921\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4351 - val_loss: 0.4907\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4334 - val_loss: 0.4888\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4318 - val_loss: 0.4879\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4304 - val_loss: 0.4858\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4289 - val_loss: 0.4851\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4278 - val_loss: 0.4826\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4264 - val_loss: 0.4803\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4251 - val_loss: 0.4790\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4237 - val_loss: 0.4778\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4225 - val_loss: 0.4761\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4212 - val_loss: 0.4761\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4202 - val_loss: 0.4737\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4189 - val_loss: 0.4713\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4180 - val_loss: 0.4713\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4168 - val_loss: 0.4697\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4157 - val_loss: 0.4683\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4147 - val_loss: 0.4672\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4137 - val_loss: 0.4659\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4128 - val_loss: 0.4647\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4116 - val_loss: 0.4631\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4109 - val_loss: 0.4630\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4099 - val_loss: 0.4613\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4088 - val_loss: 0.4606\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4082 - val_loss: 0.4590\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4073 - val_loss: 0.4582\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4064 - val_loss: 0.4568\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4056 - val_loss: 0.4564\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4046 - val_loss: 0.4565\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4040 - val_loss: 0.4553\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4031 - val_loss: 0.4539\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4024 - val_loss: 0.4530\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4017 - val_loss: 0.4516\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4008 - val_loss: 0.4500\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4001 - val_loss: 0.4499\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3993 - val_loss: 0.4506\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3987 - val_loss: 0.4486\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3978 - val_loss: 0.4486\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3972 - val_loss: 0.4464\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3964 - val_loss: 0.4469\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3960 - val_loss: 0.4457\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3953 - val_loss: 0.4456\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3946 - val_loss: 0.4440\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3939 - val_loss: 0.4439\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3934 - val_loss: 0.4428\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3926 - val_loss: 0.4411\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3922 - val_loss: 0.4412\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3914 - val_loss: 0.4413\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3907 - val_loss: 0.4394\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3903 - val_loss: 0.4393\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3897 - val_loss: 0.4389\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3892 - val_loss: 0.4376\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3886 - val_loss: 0.4371\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3881 - val_loss: 0.4372\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3874 - val_loss: 0.4357\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3867 - val_loss: 0.4370\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3864 - val_loss: 0.4351\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3859 - val_loss: 0.4338\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3852 - val_loss: 0.4329\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3844 - val_loss: 0.4324\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3841 - val_loss: 0.4320\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4053\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 128us/sample - loss: 2.8450 - val_loss: 1.4384\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.0603 - val_loss: 0.9259\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8043 - val_loss: 0.7877\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7090 - val_loss: 0.7352\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6635 - val_loss: 0.7057\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6350 - val_loss: 0.6851\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6137 - val_loss: 0.6694\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5960 - val_loss: 0.6519\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5802 - val_loss: 0.6399\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5663 - val_loss: 0.6241\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5535 - val_loss: 0.6112\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5422 - val_loss: 0.6005\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5317 - val_loss: 0.5916\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5223 - val_loss: 0.5824\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5136 - val_loss: 0.5716\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5060 - val_loss: 0.5629\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4988 - val_loss: 0.5562\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4924 - val_loss: 0.5502\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4864 - val_loss: 0.5434\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4812 - val_loss: 0.5383\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4763 - val_loss: 0.5331\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4717 - val_loss: 0.5285\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4676 - val_loss: 0.5248\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4639 - val_loss: 0.5189\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4602 - val_loss: 0.5156\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4569 - val_loss: 0.5115\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4539 - val_loss: 0.5087\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4513 - val_loss: 0.5048\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4487 - val_loss: 0.5028\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4462 - val_loss: 0.4999\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4440 - val_loss: 0.4973\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4417 - val_loss: 0.4940\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4398 - val_loss: 0.4919\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4377 - val_loss: 0.4912\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4360 - val_loss: 0.4869\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4340 - val_loss: 0.4866\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4325 - val_loss: 0.4842\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4308 - val_loss: 0.4815\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4292 - val_loss: 0.4800\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4278 - val_loss: 0.4770\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4263 - val_loss: 0.4758\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4247 - val_loss: 0.4732\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4235 - val_loss: 0.4721\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4222 - val_loss: 0.4704\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4209 - val_loss: 0.4696\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4196 - val_loss: 0.4689\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4185 - val_loss: 0.4668\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4172 - val_loss: 0.4658\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4163 - val_loss: 0.4632\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4151 - val_loss: 0.4616\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4141 - val_loss: 0.4609\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4129 - val_loss: 0.4592\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4120 - val_loss: 0.4579\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4108 - val_loss: 0.4569\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4099 - val_loss: 0.4558\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4089 - val_loss: 0.4538\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4082 - val_loss: 0.4537\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4071 - val_loss: 0.4516\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4063 - val_loss: 0.4505\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4054 - val_loss: 0.4492\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4047 - val_loss: 0.4494\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4038 - val_loss: 0.4484\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4029 - val_loss: 0.4474\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4022 - val_loss: 0.4479\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4015 - val_loss: 0.4454\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4008 - val_loss: 0.4438\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4000 - val_loss: 0.4426\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3992 - val_loss: 0.4423\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3988 - val_loss: 0.4412\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3979 - val_loss: 0.4402\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3973 - val_loss: 0.4407\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.395 - 0s 37us/sample - loss: 0.3965 - val_loss: 0.4383\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3959 - val_loss: 0.4373\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3954 - val_loss: 0.4372\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3946 - val_loss: 0.4388\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3938 - val_loss: 0.4379\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3936 - val_loss: 0.4358\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3928 - val_loss: 0.4336\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3922 - val_loss: 0.4340\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3916 - val_loss: 0.4332\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3911 - val_loss: 0.4322\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3904 - val_loss: 0.4318\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3898 - val_loss: 0.4306\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3893 - val_loss: 0.4309\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3886 - val_loss: 0.4284\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3882 - val_loss: 0.4284\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3877 - val_loss: 0.4287\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3870 - val_loss: 0.4275\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3865 - val_loss: 0.4269\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3860 - val_loss: 0.4285\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3856 - val_loss: 0.4259\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3848 - val_loss: 0.4259\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3844 - val_loss: 0.4263\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3840 - val_loss: 0.4250\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3832 - val_loss: 0.4260\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3828 - val_loss: 0.4232\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3823 - val_loss: 0.4213\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3817 - val_loss: 0.4236\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3814 - val_loss: 0.4201\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3809 - val_loss: 0.4205\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3923\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 3.6116 - val_loss: 2.4104\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.9849 - val_loss: 1.7472\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.5056 - val_loss: 1.4342\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.2618 - val_loss: 1.2348\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 1.0927 - val_loss: 1.0845\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.9637 - val_loss: 0.9663\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8684 - val_loss: 0.8793\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7977 - val_loss: 0.8155\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7470 - val_loss: 0.7702\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7104 - val_loss: 0.7370\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6840 - val_loss: 0.7147\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6639 - val_loss: 0.6969\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6486 - val_loss: 0.6828\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6364 - val_loss: 0.6725\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6261 - val_loss: 0.6634\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6173 - val_loss: 0.6552\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6095 - val_loss: 0.6486\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6023 - val_loss: 0.6418\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5959 - val_loss: 0.6358\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5897 - val_loss: 0.6300\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5837 - val_loss: 0.6241\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5782 - val_loss: 0.6193\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5731 - val_loss: 0.6143\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5681 - val_loss: 0.6101\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5635 - val_loss: 0.6048\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5589 - val_loss: 0.6003\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5546 - val_loss: 0.5965\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5503 - val_loss: 0.5940\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5465 - val_loss: 0.5900\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5427 - val_loss: 0.5858\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5390 - val_loss: 0.5838\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5356 - val_loss: 0.5795\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5324 - val_loss: 0.5762\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5292 - val_loss: 0.5731\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5260 - val_loss: 0.5707\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5230 - val_loss: 0.5681\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5202 - val_loss: 0.5644\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5175 - val_loss: 0.5613\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5148 - val_loss: 0.5590\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5123 - val_loss: 0.5568\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5098 - val_loss: 0.5545\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5075 - val_loss: 0.5524\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5052 - val_loss: 0.5508\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5030 - val_loss: 0.5478\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5008 - val_loss: 0.5460\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4989 - val_loss: 0.5445\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4969 - val_loss: 0.5429\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4949 - val_loss: 0.5401\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4930 - val_loss: 0.5388\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4911 - val_loss: 0.5370\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4893 - val_loss: 0.5356\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4876 - val_loss: 0.5338\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4859 - val_loss: 0.5317\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4844 - val_loss: 0.5314\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4827 - val_loss: 0.5294\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4811 - val_loss: 0.5270\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4796 - val_loss: 0.5260\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4782 - val_loss: 0.5245\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4767 - val_loss: 0.5233\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4752 - val_loss: 0.5222\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4738 - val_loss: 0.5213\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4724 - val_loss: 0.5186\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4711 - val_loss: 0.5167\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4698 - val_loss: 0.5157\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4683 - val_loss: 0.5137\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4672 - val_loss: 0.5143\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4659 - val_loss: 0.5128\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4646 - val_loss: 0.5105\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4634 - val_loss: 0.5103\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4621 - val_loss: 0.5082\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4610 - val_loss: 0.5069\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4598 - val_loss: 0.5062\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4587 - val_loss: 0.5045\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4575 - val_loss: 0.5031\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4563 - val_loss: 0.5023\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4552 - val_loss: 0.5003\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4541 - val_loss: 0.5001\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4531 - val_loss: 0.4986\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4521 - val_loss: 0.4978\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4510 - val_loss: 0.4972\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4499 - val_loss: 0.4956\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4488 - val_loss: 0.4936\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4479 - val_loss: 0.4936\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4468 - val_loss: 0.4937\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4458 - val_loss: 0.4900\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4447 - val_loss: 0.4907\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4439 - val_loss: 0.4907\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4429 - val_loss: 0.4875\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4420 - val_loss: 0.4869\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4410 - val_loss: 0.4857\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4401 - val_loss: 0.4863\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4392 - val_loss: 0.4843\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4385 - val_loss: 0.4835\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4374 - val_loss: 0.4813\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4366 - val_loss: 0.4815\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4355 - val_loss: 0.4817\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4349 - val_loss: 0.4785\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4339 - val_loss: 0.4780\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4332 - val_loss: 0.4780\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4323 - val_loss: 0.4773\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.4264\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 3.7257 - val_loss: 2.5708\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 1.8643 - val_loss: 1.5337\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 1.2776 - val_loss: 1.1890\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.0226 - val_loss: 0.9896\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.8628 - val_loss: 0.8614\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.7591 - val_loss: 0.7790\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6925 - val_loss: 0.7277\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6490 - val_loss: 0.6933\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6192 - val_loss: 0.6698\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5976 - val_loss: 0.6518\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5808 - val_loss: 0.6375\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5669 - val_loss: 0.6249\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5546 - val_loss: 0.6135\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5438 - val_loss: 0.6035\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5339 - val_loss: 0.5939\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5251 - val_loss: 0.5853\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5170 - val_loss: 0.5774\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5098 - val_loss: 0.5700\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5031 - val_loss: 0.5633\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4970 - val_loss: 0.5571\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4915 - val_loss: 0.5516\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4865 - val_loss: 0.5469\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4821 - val_loss: 0.5422\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4781 - val_loss: 0.5378\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4745 - val_loss: 0.5341\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4712 - val_loss: 0.5305\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4685 - val_loss: 0.5277\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4658 - val_loss: 0.5250\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4634 - val_loss: 0.5218\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4612 - val_loss: 0.5193\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4591 - val_loss: 0.5173\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4573 - val_loss: 0.5151\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4555 - val_loss: 0.5130\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4538 - val_loss: 0.5111\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4523 - val_loss: 0.5096\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4507 - val_loss: 0.5079\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4494 - val_loss: 0.5063\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4481 - val_loss: 0.5044\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4469 - val_loss: 0.5030\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4457 - val_loss: 0.5014\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4446 - val_loss: 0.5001\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4434 - val_loss: 0.4988\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4424 - val_loss: 0.4978\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4413 - val_loss: 0.4962\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4404 - val_loss: 0.4956\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4396 - val_loss: 0.4942\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4387 - val_loss: 0.4929\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4378 - val_loss: 0.4918\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4369 - val_loss: 0.4906\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4361 - val_loss: 0.4899\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4353 - val_loss: 0.4895\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4346 - val_loss: 0.4878\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4338 - val_loss: 0.4865\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4333 - val_loss: 0.4858\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4325 - val_loss: 0.4851\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4317 - val_loss: 0.4840\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4312 - val_loss: 0.4833\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4305 - val_loss: 0.4822\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4299 - val_loss: 0.4818\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4292 - val_loss: 0.4807\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4287 - val_loss: 0.4806\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4281 - val_loss: 0.4794\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4273 - val_loss: 0.4785\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4269 - val_loss: 0.4776\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4263 - val_loss: 0.4769\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4257 - val_loss: 0.4761\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4252 - val_loss: 0.4756\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4246 - val_loss: 0.4753\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4241 - val_loss: 0.4747\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4235 - val_loss: 0.4737\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4230 - val_loss: 0.4732\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4224 - val_loss: 0.4723\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4218 - val_loss: 0.4714\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4214 - val_loss: 0.4710\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4208 - val_loss: 0.4711\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4203 - val_loss: 0.4697\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4197 - val_loss: 0.4696\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4193 - val_loss: 0.4684\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4187 - val_loss: 0.4682\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4183 - val_loss: 0.4678\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4178 - val_loss: 0.4672\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4173 - val_loss: 0.4662\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4168 - val_loss: 0.4658\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4163 - val_loss: 0.4659\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4156 - val_loss: 0.4643\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4153 - val_loss: 0.4639\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4148 - val_loss: 0.4639\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4142 - val_loss: 0.4627\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4139 - val_loss: 0.4625\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4134 - val_loss: 0.4623\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4129 - val_loss: 0.4616\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4125 - val_loss: 0.4611\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4120 - val_loss: 0.4606\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4116 - val_loss: 0.4599\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4109 - val_loss: 0.4605\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4107 - val_loss: 0.4596\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4103 - val_loss: 0.4583\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4097 - val_loss: 0.4577\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4090 - val_loss: 0.4570\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4088 - val_loss: 0.4569\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.4287\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 3.1322 - val_loss: 1.8787\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 1.2440 - val_loss: 1.1016\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8950 - val_loss: 0.8976\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7850 - val_loss: 0.8086\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7265 - val_loss: 0.7594\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6900 - val_loss: 0.7300\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6651 - val_loss: 0.7114\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6463 - val_loss: 0.6952\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6306 - val_loss: 0.6837\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6173 - val_loss: 0.6715\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6053 - val_loss: 0.6608\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5950 - val_loss: 0.6519\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5854 - val_loss: 0.6441\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5769 - val_loss: 0.6360\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5688 - val_loss: 0.6275\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5619 - val_loss: 0.6204\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5550 - val_loss: 0.6136\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5487 - val_loss: 0.6073\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5426 - val_loss: 0.6013\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5370 - val_loss: 0.5953\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5315 - val_loss: 0.5901\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5263 - val_loss: 0.5850\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5216 - val_loss: 0.5800\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5170 - val_loss: 0.5741\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5126 - val_loss: 0.5696\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5083 - val_loss: 0.5648\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5044 - val_loss: 0.5609\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5008 - val_loss: 0.5566\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4972 - val_loss: 0.5525\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4937 - val_loss: 0.5484\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4906 - val_loss: 0.5449\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4874 - val_loss: 0.5409\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4846 - val_loss: 0.5376\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4817 - val_loss: 0.5351\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4791 - val_loss: 0.5307\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4766 - val_loss: 0.5282\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4741 - val_loss: 0.5251\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4717 - val_loss: 0.5218\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4694 - val_loss: 0.5195\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4673 - val_loss: 0.5162\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4652 - val_loss: 0.5136\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4630 - val_loss: 0.5108\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4612 - val_loss: 0.5085\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4592 - val_loss: 0.5060\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4574 - val_loss: 0.5041\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4556 - val_loss: 0.5026\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4540 - val_loss: 0.4996\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4522 - val_loss: 0.4981\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4508 - val_loss: 0.4951\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4492 - val_loss: 0.4933\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4478 - val_loss: 0.4912\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4462 - val_loss: 0.4895\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4449 - val_loss: 0.4877\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4434 - val_loss: 0.4859\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4421 - val_loss: 0.4845\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4405 - val_loss: 0.4825\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4397 - val_loss: 0.4811\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4384 - val_loss: 0.4796\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4372 - val_loss: 0.4780\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4360 - val_loss: 0.4766\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4349 - val_loss: 0.4754\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4338 - val_loss: 0.4740\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4326 - val_loss: 0.4728\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4316 - val_loss: 0.4724\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4305 - val_loss: 0.4702\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4296 - val_loss: 0.4689\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4285 - val_loss: 0.4676\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4274 - val_loss: 0.4667\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4266 - val_loss: 0.4652\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4256 - val_loss: 0.4642\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4247 - val_loss: 0.4636\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4236 - val_loss: 0.4618\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4229 - val_loss: 0.4608\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4220 - val_loss: 0.4600\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4210 - val_loss: 0.4604\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4201 - val_loss: 0.4594\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4195 - val_loss: 0.4574\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4184 - val_loss: 0.4560\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4177 - val_loss: 0.4556\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4169 - val_loss: 0.4547\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4160 - val_loss: 0.4537\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4152 - val_loss: 0.4534\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4145 - val_loss: 0.4519\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4137 - val_loss: 0.4517\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4128 - val_loss: 0.4498\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4123 - val_loss: 0.4491\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4117 - val_loss: 0.4489\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4107 - val_loss: 0.4476\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4102 - val_loss: 0.4474\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4095 - val_loss: 0.4479\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4089 - val_loss: 0.4456\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4081 - val_loss: 0.4459\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4076 - val_loss: 0.4454\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4071 - val_loss: 0.4440\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4062 - val_loss: 0.4447\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4057 - val_loss: 0.4424\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4052 - val_loss: 0.4415\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4044 - val_loss: 0.4424\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4041 - val_loss: 0.4403\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4035 - val_loss: 0.4400\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.4119\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.7872 - val_loss: 0.6338\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5679 - val_loss: 0.6172\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5466 - val_loss: 0.5870\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5384 - val_loss: 0.5713\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5368 - val_loss: 0.5715\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5306 - val_loss: 0.5653\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5442 - val_loss: 0.5591\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5945 - val_loss: 0.6062\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.6875 - val_loss: 0.6507\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 1.2673 - val_loss: 0.6874\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 3.5814 - val_loss: 0.6147\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 13.2131 - val_loss: 0.9881\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 48.3688 - val_loss: 2.0389\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 200.8138 - val_loss: 4.9679\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 798.9690 - val_loss: 13.4978\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 3113.8433 - val_loss: 66.3647\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 12074.8704 - val_loss: 305.6621\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 41827.3889\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.8466 - val_loss: 0.6293\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5565 - val_loss: 0.5839\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5367 - val_loss: 0.5749\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5233 - val_loss: 0.5654\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5183 - val_loss: 0.5721\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5144 - val_loss: 0.5595\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5135 - val_loss: 0.5545\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5214 - val_loss: 0.5699\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5111 - val_loss: 0.6411\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5165 - val_loss: 0.5614\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5106 - val_loss: 0.6829\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5144 - val_loss: 0.5520\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5209 - val_loss: 0.5594\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5186 - val_loss: 0.5615\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5147 - val_loss: 0.5557\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5202 - val_loss: 0.5577\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5165 - val_loss: 0.5918\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5181 - val_loss: 0.6131\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5157 - val_loss: 0.5694\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5121 - val_loss: 0.5507\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5180 - val_loss: 0.5598\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5133 - val_loss: 0.6297\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5187 - val_loss: 0.7044\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5229 - val_loss: 0.6479\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5172 - val_loss: 0.6136\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5146 - val_loss: 0.6523\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5105 - val_loss: 0.5492\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5208 - val_loss: 0.7243\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5231 - val_loss: 0.6891\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5169 - val_loss: 0.7112\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5198 - val_loss: 0.5933\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5167 - val_loss: 0.5695\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5200 - val_loss: 0.6045\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5164 - val_loss: 0.5635\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5100 - val_loss: 0.7086\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5195 - val_loss: 0.5652\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5221 - val_loss: 0.5709\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.5267\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 98us/sample - loss: 1.9880 - val_loss: 0.6617\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5723 - val_loss: 0.6043\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5467 - val_loss: 0.5880\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5332 - val_loss: 0.5818\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5251 - val_loss: 0.5698\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5196 - val_loss: 0.5658\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5165 - val_loss: 0.5694\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5149 - val_loss: 0.5592\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5130 - val_loss: 0.5656\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5125 - val_loss: 0.5689\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5117 - val_loss: 0.5556\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5120 - val_loss: 0.5563\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5116 - val_loss: 0.5592\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5113 - val_loss: 0.5570\n",
      "Epoch 15/100\n",
      "  32/7740 [..............................] - ETA: 0s - loss: 0.4590WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-41ff3e64d6b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m rnd_search_cv.fit(X_train_sc, y_train, epochs=100,\n\u001b[0;32m     11\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\deeplearningaz\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "\n",
    "rnd_search_cv.fit(X_train_sc, y_train, epochs=100,\n",
    "                  validation_data=(X_valid_sc, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
